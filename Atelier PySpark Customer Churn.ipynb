{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d51ab60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
      "     ------------------------------------ 316.9/316.9 MB 718.2 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting py4j==0.10.9.7\n",
      "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "     ------------------------------------ 200.5/200.5 kB 468.6 kB/s eta 0:00:00\n",
      "Building wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py): started\n",
      "  Building wheel for pyspark (setup.py): still running...\n",
      "  Building wheel for pyspark (setup.py): finished with status 'done'\n",
      "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425367 sha256=1650c4a0f300b71f15b4e029ecb22d2604d45dfd5928b8eb6e11ea4030405118\n",
      "  Stored in directory: c:\\users\\naima\\appdata\\local\\pip\\cache\\wheels\\23\\6e\\46\\d22b2a968d8ca06247fd42f04d40a95741472068160bdd46dd\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.7 pyspark-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35974bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark[pandas_on_spark] in c:\\users\\naima\\anaconda3\\envs\\ml\\lib\\site-packages (3.5.0)\n",
      "Collecting plotly\n",
      "  Downloading plotly-5.17.0-py2.py3-none-any.whl (15.6 MB)\n",
      "     --------------------------------------- 15.6/15.6 MB 74.9 kB/s eta 0:00:00\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\naima\\anaconda3\\envs\\ml\\lib\\site-packages (from pyspark[pandas_on_spark]) (0.10.9.7)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\naima\\anaconda3\\envs\\ml\\lib\\site-packages (from pyspark[pandas_on_spark]) (1.23.5)\n",
      "Collecting pyarrow>=4.0.0\n",
      "  Downloading pyarrow-13.0.0-cp39-cp39-win_amd64.whl (24.4 MB)\n",
      "     -------------------------------------- 24.4/24.4 MB 139.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: pandas>=1.0.5 in c:\\users\\naima\\anaconda3\\envs\\ml\\lib\\site-packages (from pyspark[pandas_on_spark]) (1.5.3)\n",
      "Collecting tenacity>=6.2.0\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\naima\\anaconda3\\envs\\ml\\lib\\site-packages (from plotly) (22.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\naima\\anaconda3\\envs\\ml\\lib\\site-packages (from pandas>=1.0.5->pyspark[pandas_on_spark]) (2022.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\naima\\anaconda3\\envs\\ml\\lib\\site-packages (from pandas>=1.0.5->pyspark[pandas_on_spark]) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\naima\\anaconda3\\envs\\ml\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=1.0.5->pyspark[pandas_on_spark]) (1.16.0)\n",
      "Installing collected packages: tenacity, pyarrow, plotly\n",
      "Successfully installed plotly-5.17.0 pyarrow-13.0.0 tenacity-8.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark[pandas_on_spark] plotly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c49d18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73d23902",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark= SparkSession.builder.appName('Customers').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "191fa1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=spark.read.csv(\"customer_churn.csv\",inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6957a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Names: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Total_Purchase: double (nullable = true)\n",
      " |-- Account_Manager: integer (nullable = true)\n",
      " |-- Years: double (nullable = true)\n",
      " |-- Num_Sites: double (nullable = true)\n",
      " |-- Onboard_date: timestamp (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Company: string (nullable = true)\n",
      " |-- Churn: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e08bce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+-----------------+-----------------+------------------+-----------------+------------------+--------------------+--------------------+-------------------+\n",
      "|summary|        Names|              Age|   Total_Purchase|   Account_Manager|            Years|         Num_Sites|            Location|             Company|              Churn|\n",
      "+-------+-------------+-----------------+-----------------+------------------+-----------------+------------------+--------------------+--------------------+-------------------+\n",
      "|  count|          900|              900|              900|               900|              900|               900|                 900|                 900|                900|\n",
      "|   mean|         NULL|41.81666666666667|10062.82403333334|0.4811111111111111| 5.27315555555555| 8.587777777777777|                NULL|                NULL|0.16666666666666666|\n",
      "| stddev|         NULL|6.127560416916251|2408.644531858096|0.4999208935073339|1.274449013194616|1.7648355920350969|                NULL|                NULL| 0.3728852122772358|\n",
      "|    min|   Aaron King|             22.0|            100.0|                 0|              1.0|               3.0|00103 Jeffrey Cre...|     Abbott-Thompson|                  0|\n",
      "|    max|Zachary Walsh|             65.0|         18026.01|                 1|             9.15|              14.0|Unit 9800 Box 287...|Zuniga, Clark and...|                  1|\n",
      "+-------+-------------+-----------------+-----------------+------------------+-----------------+------------------+--------------------+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f151f201",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a37e629",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler=VectorAssembler(inputCols=['Age', \n",
    " 'Total_Purchase', \n",
    " 'Account_Manager', \n",
    " 'Years', \n",
    " 'Num_Sites'], \n",
    "outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f84490a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output=assembler.transform(dataset) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76bfc431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|churn|\n",
      "+--------------------+-----+\n",
      "|[42.0,11066.8,0.0...|    1|\n",
      "|[41.0,11916.22,0....|    1|\n",
      "|[38.0,12884.75,0....|    1|\n",
      "|[42.0,8010.76,0.0...|    1|\n",
      "|[37.0,9191.58,0.0...|    1|\n",
      "|[48.0,10356.02,0....|    1|\n",
      "|[44.0,11331.58,1....|    1|\n",
      "|[32.0,9885.12,1.0...|    1|\n",
      "|[43.0,14062.6,1.0...|    1|\n",
      "|[40.0,8066.94,1.0...|    1|\n",
      "|[30.0,11575.37,1....|    1|\n",
      "|[45.0,8771.02,1.0...|    1|\n",
      "|[45.0,8988.67,1.0...|    1|\n",
      "|[40.0,8283.32,1.0...|    1|\n",
      "|[41.0,6569.87,1.0...|    1|\n",
      "|[38.0,10494.82,1....|    1|\n",
      "|[45.0,8213.41,1.0...|    1|\n",
      "|[43.0,11226.88,0....|    1|\n",
      "|[53.0,5515.09,0.0...|    1|\n",
      "|[46.0,8046.4,1.0,...|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_final = output.select(\"features\",\"churn\") \n",
    "df_final.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "959e3ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test=df_final.randomSplit([0.7,0.3], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb93f54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c768646a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(labelCol=\"churn\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b762d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrm = lr.fit(train) \n",
    "lrm_summary = lrm.summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3578349e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            features|churn|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|[22.0,11254.38,1....|  0.0|[4.55979963242690...|[0.98964420919358...|       0.0|\n",
      "|[25.0,9672.03,0.0...|  0.0|[4.67536757133125...|[0.99076400091638...|       0.0|\n",
      "|[26.0,8939.61,0.0...|  0.0|[6.28230440567531...|[0.99813439848473...|       0.0|\n",
      "|[27.0,8628.8,1.0,...|  0.0|[5.32554251161008...|[0.99515784990742...|       0.0|\n",
      "|[28.0,8670.98,0.0...|  0.0|[7.59026200904824...|[0.99949490661754...|       0.0|\n",
      "|[28.0,11128.95,1....|  0.0|[4.09749022712613...|[0.98365720318515...|       0.0|\n",
      "|[29.0,5900.78,1.0...|  0.0|[4.06733742325029...|[0.98316533957374...|       0.0|\n",
      "|[29.0,8688.17,1.0...|  1.0|[2.71962101743711...|[0.93817455523842...|       0.0|\n",
      "|[29.0,9378.24,0.0...|  0.0|[4.73007562142385...|[0.99125140974466...|       0.0|\n",
      "|[29.0,12711.15,0....|  0.0|[5.26411648016011...|[0.99485266978467...|       0.0|\n",
      "|[29.0,13240.01,1....|  0.0|[6.47472510820143...|[0.99846045112441...|       0.0|\n",
      "|[29.0,13255.05,1....|  0.0|[4.04666631207395...|[0.98281976763204...|       0.0|\n",
      "|[30.0,7960.64,1.0...|  1.0|[3.13526575434993...|[0.95832420978025...|       0.0|\n",
      "|[30.0,8677.28,1.0...|  0.0|[4.06908153506488...|[0.98319418249941...|       0.0|\n",
      "|[30.0,10744.14,1....|  1.0|[1.77952269189110...|[0.85563791802161...|       0.0|\n",
      "|[30.0,10960.52,1....|  0.0|[2.40247407103320...|[0.91701576933689...|       0.0|\n",
      "|[30.0,11575.37,1....|  1.0|[3.89386120765316...|[0.98003996266427...|       0.0|\n",
      "|[31.0,5387.75,0.0...|  0.0|[2.66975170329194...|[0.93521798988786...|       0.0|\n",
      "|[31.0,8688.21,0.0...|  0.0|[6.48214956423210...|[0.99847182170736...|       0.0|\n",
      "|[31.0,10058.87,1....|  0.0|[4.34147270545396...|[0.98714993040074...|       0.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lrm_summary.predictions.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "516d4e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------------------+\n",
      "|summary|             churn|         prediction|\n",
      "+-------+------------------+-------------------+\n",
      "|  count|               667|                667|\n",
      "|   mean|0.1634182908545727|0.12293853073463268|\n",
      "| stddev|0.3700243606477147|0.32861306618408714|\n",
      "|    min|               0.0|                0.0|\n",
      "|    max|               1.0|                1.0|\n",
      "+-------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lrm_summary.predictions.describe().show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73171f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31ed9d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = lrm.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93c7a616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            features|churn|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|[26.0,8787.39,1.0...|    1|[0.79106248132020...|[0.68805942038441...|       0.0|\n",
      "|[28.0,9090.43,1.0...|    0|[1.61026688857555...|[0.83344843709585...|       0.0|\n",
      "|[28.0,11204.23,0....|    0|[1.97148345642762...|[0.87777036176974...|       0.0|\n",
      "|[28.0,11245.38,0....|    0|[3.75331012854098...|[0.97709682330471...|       0.0|\n",
      "|[29.0,9617.59,0.0...|    0|[4.42202807822147...|[0.98813267415840...|       0.0|\n",
      "|[29.0,10203.18,1....|    0|[3.71080419195967...|[0.97612605863733...|       0.0|\n",
      "|[29.0,11274.46,1....|    0|[4.39058463869248...|[0.98775823667280...|       0.0|\n",
      "|[30.0,6744.87,0.0...|    0|[3.55749267043437...|[0.97228008128416...|       0.0|\n",
      "|[30.0,8403.78,1.0...|    0|[5.76304568829245...|[0.99686830940139...|       0.0|\n",
      "|[30.0,8874.83,0.0...|    0|[3.22709763405856...|[0.96184137137662...|       0.0|\n",
      "|[30.0,10183.98,1....|    0|[2.87524813075598...|[0.94660921217089...|       0.0|\n",
      "|[30.0,12788.37,0....|    0|[2.55636649637210...|[0.92800005897191...|       0.0|\n",
      "|[30.0,13473.35,0....|    0|[2.76977890817312...|[0.94102071697444...|       0.0|\n",
      "|[31.0,5304.6,0.0,...|    0|[3.48758770685489...|[0.97033253112331...|       0.0|\n",
      "|[31.0,7073.61,0.0...|    0|[3.16501389037818...|[0.95949625177380...|       0.0|\n",
      "|[31.0,8829.83,1.0...|    0|[4.33951413571566...|[0.98712506233162...|       0.0|\n",
      "|[31.0,9574.89,0.0...|    0|[3.31877005992135...|[0.96506715076717...|       0.0|\n",
      "|[31.0,11743.24,0....|    0|[6.54958239216506...|[0.99857133106464...|       0.0|\n",
      "|[32.0,6367.22,1.0...|    0|[3.02498369579995...|[0.95369013007749...|       0.0|\n",
      "|[32.0,7896.65,0.0...|    0|[3.45646309561266...|[0.96942330053394...|       0.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_labels.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01fff9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval = BinaryClassificationEvaluator(rawPredictionCol='prediction',labelCol='churn') \n",
    "auc = eval.evaluate(pred_labels.predictions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1323119c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7456808943089431"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "633936a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers = spark.read.csv('new_customers_test.csv',inferSchema=True, header=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4265a37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Names: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Total_Purchase: double (nullable = true)\n",
      " |-- Account_Manager: integer (nullable = true)\n",
      " |-- Years: double (nullable = true)\n",
      " |-- Num_Sites: double (nullable = true)\n",
      " |-- Onboard_date: timestamp (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Company: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_model = lr.fit(df_final) \n",
    "customers.printSchema() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b44e0d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Names: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Total_Purchase: double (nullable = true)\n",
      " |-- Account_Manager: integer (nullable = true)\n",
      " |-- Years: double (nullable = true)\n",
      " |-- Num_Sites: double (nullable = true)\n",
      " |-- Onboard_date: timestamp (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Company: string (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customers_valid = assembler.transform(customers) \n",
    "customers_valid.printSchema() \n",
    "res = final_model.transform(customers_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e2976e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------+\n",
      "|         Company|prediction|\n",
      "+----------------+----------+\n",
      "|        King Ltd|       0.0|\n",
      "|   Cannon-Benson|       1.0|\n",
      "|Barron-Robertson|       1.0|\n",
      "|   Sexton-Golden|       1.0|\n",
      "|        Wood LLC|       0.0|\n",
      "|   Parks-Robbins|       1.0|\n",
      "+----------------+----------+\n",
      "\n",
      "+--------------+----------+\n",
      "|         Names|prediction|\n",
      "+--------------+----------+\n",
      "| Andrew Mccall|       0.0|\n",
      "|Michele Wright|       1.0|\n",
      "|  Jeremy Chang|       1.0|\n",
      "|Megan Ferguson|       1.0|\n",
      "|  Taylor Young|       0.0|\n",
      "| Jessica Drake|       1.0|\n",
      "+--------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res.select('Company','prediction').show() \n",
    "res.select('Names','prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af28aea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
